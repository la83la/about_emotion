{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "dd0058dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy  # https://github.com/tweepy/tweepy\n",
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import datetime\n",
    "from pytz import timezone\n",
    "import hashlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff38a45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication OK\n"
     ]
    }
   ],
   "source": [
    "# CREDENTIALS\n",
    "api_key = \"zGWacA8CkRVNQgY5vgAh4nfAp\"\n",
    "api_secret_key = \"DWaRZpAls3u4YcotLKcImKeYy03qlcBqXBKlDr6CtK5Y33Jc3I\"\n",
    "access_token = \"1140211942436429825-5D5hkMjOGr5WyxciM8qO7WH6lz0cOq\"\n",
    "access_token_secret = \"AZZ0OhhV2t8W1n9Q8MqopgtvZaChXsZzxwr1CbF9OmcIz\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret_key)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print(\"Authentication OK\")\n",
    "except:\n",
    "    print(\"Error during authentication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6d30377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total 33 companied of DJIA\n",
    "companies = \"3M,Walgreens,Salesforce,Amgen,Honeywell,American Express,Apple,Boeing,Caterpillar,Chevron,Cisco Systems,\" \\\n",
    "            \"Coca-Cola,ExxonMobil,General Electric,Goldman Sachs,IBM,\" \\\n",
    "            \"Intel,Johnson & Johnson,JPMorgan Chase,McDonald's,Merck,Microsoft,Nike,\" \\\n",
    "            \"Pfizer,Procter & Gamble,The Home Depot,Travelers,United Technologies,\" \\\n",
    "            \"UnitedHealth Group,Verizon,Visa,Walmart,Walt Disney\".split(\",\")\n",
    "\n",
    "accounts = \"3M,Walgreens,Salesforce,Amgen,Honeywell,AmericanExpress,AppleSupport,Boeing,CaterpillarInc,Chevron,Cisco,\" \\\n",
    "           \"CocaCola,exxonmobil,generalelectric,GoldmanSachs,IBM,intel,\" \\\n",
    "           \"JNJNews,jpmorgan,McDonalds,Merck,Microsoft,Nike,pfizer,ProcterGamble,\" \\\n",
    "           \"HomeDepot,Travelers,UTC,UnitedHealthGrp,verizon,Visa,Walmart,DisneyStudios\".split(\",\")\n",
    "\n",
    "comDic = dict(zip(accounts, companies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9ba40b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3M': '3M',\n",
       " 'Walgreens': 'Walgreens',\n",
       " 'Salesforce': 'Salesforce',\n",
       " 'Amgen': 'Amgen',\n",
       " 'Honeywell': 'Honeywell',\n",
       " 'AmericanExpress': 'American Express',\n",
       " 'AppleSupport': 'Apple',\n",
       " 'Boeing': 'Boeing',\n",
       " 'CaterpillarInc': 'Caterpillar',\n",
       " 'Chevron': 'Chevron',\n",
       " 'Cisco': 'Cisco Systems',\n",
       " 'CocaCola': 'Coca-Cola',\n",
       " 'exxonmobil': 'ExxonMobil',\n",
       " 'generalelectric': 'General Electric',\n",
       " 'GoldmanSachs': 'Goldman Sachs',\n",
       " 'IBM': 'IBM',\n",
       " 'intel': 'Intel',\n",
       " 'JNJNews': 'Johnson & Johnson',\n",
       " 'jpmorgan': 'JPMorgan Chase',\n",
       " 'McDonalds': \"McDonald's\",\n",
       " 'Merck': 'Merck',\n",
       " 'Microsoft': 'Microsoft',\n",
       " 'Nike': 'Nike',\n",
       " 'pfizer': 'Pfizer',\n",
       " 'ProcterGamble': 'Procter & Gamble',\n",
       " 'HomeDepot': 'The Home Depot',\n",
       " 'Travelers': 'Travelers',\n",
       " 'UTC': 'United Technologies',\n",
       " 'UnitedHealthGrp': 'UnitedHealth Group',\n",
       " 'verizon': 'Verizon',\n",
       " 'Visa': 'Visa',\n",
       " 'Walmart': 'Walmart',\n",
       " 'DisneyStudios': 'Walt Disney'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "746f6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the tweets base on their screen_name(user_id)\n",
    "def get_all_tweets(screen_name):\n",
    "    # Twitter only allows access to a users most recent 3200 tweets with this method\n",
    "\n",
    "    print(\"collecting tweets from: \" + screen_name)\n",
    "    # initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []\n",
    "\n",
    "    # make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name=screen_name, count=200)\n",
    "\n",
    "    # save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    # save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    # keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        # all subsequent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name=screen_name, count=200,\n",
    "                                       max_id=oldest, exclude_replies=True)\n",
    "\n",
    "        # save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        # update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        print(\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "\n",
    "    # transform the tweepy tweets into a 2D array that will populate the csv\n",
    "    outtweets = [[\n",
    "        tweet.created_at,\n",
    "        comDic[screen_name],\n",
    "        \"https://twitter.com/\" + screen_name + \"/status/\" + tweet.id_str,\n",
    "        tweet.text.encode(\"utf-8\"),\n",
    "        tweet.retweet_count,\n",
    "        tweet.favorite_count,\n",
    "        tweet.id_str]\n",
    "        for tweet in alltweets]\n",
    "\n",
    "    # compose dataframe for outputting\n",
    "    df = pd.DataFrame(columns=[\"created_at\", \"company\", \"url\", \"tweets\", \"re_tweets\", \"likes\", \"id\"])\n",
    "    for tweet in outtweets:\n",
    "        row = pd.Series(tweet,index=[\"created_at\", \"company\", \"url\", \"tweets\", \"re_tweets\", \"likes\", \"id\"])\n",
    "        df = df.append(row, ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e5fd7b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting tweets from: 3M\n",
      "...254 tweets downloaded so far\n",
      "...294 tweets downloaded so far\n",
      "...355 tweets downloaded so far\n",
      "...408 tweets downloaded so far\n",
      "...467 tweets downloaded so far\n",
      "...534 tweets downloaded so far\n",
      "...576 tweets downloaded so far\n",
      "...622 tweets downloaded so far\n",
      "...678 tweets downloaded so far\n",
      "...727 tweets downloaded so far\n",
      "...749 tweets downloaded so far\n",
      "...766 tweets downloaded so far\n",
      "...799 tweets downloaded so far\n",
      "...831 tweets downloaded so far\n",
      "...863 tweets downloaded so far\n",
      "...893 tweets downloaded so far\n",
      "...893 tweets downloaded so far\n",
      "collecting tweets from: Walgreens\n",
      "...206 tweets downloaded so far\n",
      "...207 tweets downloaded so far\n",
      "...209 tweets downloaded so far\n",
      "...210 tweets downloaded so far\n",
      "...211 tweets downloaded so far\n",
      "...212 tweets downloaded so far\n",
      "...214 tweets downloaded so far\n",
      "...225 tweets downloaded so far\n",
      "...229 tweets downloaded so far\n",
      "...236 tweets downloaded so far\n",
      "...246 tweets downloaded so far\n",
      "...250 tweets downloaded so far\n",
      "...257 tweets downloaded so far\n",
      "...261 tweets downloaded so far\n",
      "...265 tweets downloaded so far\n",
      "...265 tweets downloaded so far\n",
      "collecting tweets from: Salesforce\n",
      "...253 tweets downloaded so far\n",
      "...333 tweets downloaded so far\n",
      "...437 tweets downloaded so far\n",
      "...578 tweets downloaded so far\n",
      "...627 tweets downloaded so far\n",
      "...752 tweets downloaded so far\n",
      "...861 tweets downloaded so far\n",
      "...922 tweets downloaded so far\n",
      "...939 tweets downloaded so far\n",
      "...985 tweets downloaded so far\n",
      "...1059 tweets downloaded so far\n",
      "...1060 tweets downloaded so far\n",
      "...1060 tweets downloaded so far\n",
      "collecting tweets from: Amgen\n",
      "...383 tweets downloaded so far\n",
      "...544 tweets downloaded so far\n",
      "...735 tweets downloaded so far\n",
      "...932 tweets downloaded so far\n",
      "...1126 tweets downloaded so far\n",
      "...1312 tweets downloaded so far\n",
      "...1506 tweets downloaded so far\n",
      "...1665 tweets downloaded so far\n",
      "...1833 tweets downloaded so far\n",
      "...1974 tweets downloaded so far\n",
      "...2147 tweets downloaded so far\n",
      "...2284 tweets downloaded so far\n",
      "...2462 tweets downloaded so far\n",
      "...2647 tweets downloaded so far\n",
      "...2820 tweets downloaded so far\n",
      "...2868 tweets downloaded so far\n",
      "...2868 tweets downloaded so far\n",
      "collecting tweets from: Honeywell\n",
      "...251 tweets downloaded so far\n",
      "...313 tweets downloaded so far\n",
      "...362 tweets downloaded so far\n",
      "...420 tweets downloaded so far\n",
      "...463 tweets downloaded so far\n",
      "...495 tweets downloaded so far\n",
      "...530 tweets downloaded so far\n",
      "...573 tweets downloaded so far\n",
      "...606 tweets downloaded so far\n",
      "...629 tweets downloaded so far\n",
      "...686 tweets downloaded so far\n",
      "...757 tweets downloaded so far\n",
      "...871 tweets downloaded so far\n",
      "...990 tweets downloaded so far\n",
      "...1176 tweets downloaded so far\n",
      "...1268 tweets downloaded so far\n",
      "...1268 tweets downloaded so far\n",
      "collecting tweets from: AmericanExpress\n",
      "...224 tweets downloaded so far\n",
      "...253 tweets downloaded so far\n",
      "...284 tweets downloaded so far\n",
      "...302 tweets downloaded so far\n",
      "...353 tweets downloaded so far\n",
      "...408 tweets downloaded so far\n",
      "...436 tweets downloaded so far\n",
      "...485 tweets downloaded so far\n",
      "...510 tweets downloaded so far\n",
      "...563 tweets downloaded so far\n",
      "...598 tweets downloaded so far\n",
      "...637 tweets downloaded so far\n",
      "...676 tweets downloaded so far\n",
      "...700 tweets downloaded so far\n",
      "...759 tweets downloaded so far\n",
      "...788 tweets downloaded so far\n",
      "...788 tweets downloaded so far\n",
      "collecting tweets from: AppleSupport\n",
      "...201 tweets downloaded so far\n",
      "...202 tweets downloaded so far\n",
      "...203 tweets downloaded so far\n",
      "...204 tweets downloaded so far\n",
      "...205 tweets downloaded so far\n",
      "...206 tweets downloaded so far\n",
      "...207 tweets downloaded so far\n",
      "...208 tweets downloaded so far\n",
      "...209 tweets downloaded so far\n",
      "...211 tweets downloaded so far\n",
      "...212 tweets downloaded so far\n",
      "...212 tweets downloaded so far\n",
      "collecting tweets from: Boeing\n",
      "...363 tweets downloaded so far\n",
      "...496 tweets downloaded so far\n",
      "...683 tweets downloaded so far\n",
      "...862 tweets downloaded so far\n",
      "...1053 tweets downloaded so far\n",
      "...1233 tweets downloaded so far\n",
      "...1346 tweets downloaded so far\n",
      "...1512 tweets downloaded so far\n",
      "...1710 tweets downloaded so far\n",
      "...1899 tweets downloaded so far\n",
      "...2092 tweets downloaded so far\n",
      "...2292 tweets downloaded so far\n",
      "...2490 tweets downloaded so far\n",
      "...2675 tweets downloaded so far\n",
      "...2862 tweets downloaded so far\n",
      "...2932 tweets downloaded so far\n",
      "...2932 tweets downloaded so far\n",
      "collecting tweets from: CaterpillarInc\n",
      "...315 tweets downloaded so far\n",
      "...460 tweets downloaded so far\n",
      "...591 tweets downloaded so far\n",
      "...734 tweets downloaded so far\n",
      "...885 tweets downloaded so far\n",
      "...954 tweets downloaded so far\n",
      "...1012 tweets downloaded so far\n",
      "...1144 tweets downloaded so far\n",
      "...1298 tweets downloaded so far\n",
      "...1454 tweets downloaded so far\n",
      "...1607 tweets downloaded so far\n",
      "...1732 tweets downloaded so far\n",
      "...1845 tweets downloaded so far\n",
      "...1976 tweets downloaded so far\n",
      "...2139 tweets downloaded so far\n",
      "...2190 tweets downloaded so far\n",
      "...2190 tweets downloaded so far\n",
      "collecting tweets from: Chevron\n",
      "...279 tweets downloaded so far\n",
      "...334 tweets downloaded so far\n",
      "...379 tweets downloaded so far\n",
      "...429 tweets downloaded so far\n",
      "...461 tweets downloaded so far\n",
      "...509 tweets downloaded so far\n",
      "...564 tweets downloaded so far\n",
      "...630 tweets downloaded so far\n",
      "...718 tweets downloaded so far\n",
      "...811 tweets downloaded so far\n",
      "...881 tweets downloaded so far\n",
      "...955 tweets downloaded so far\n",
      "...1043 tweets downloaded so far\n",
      "...1102 tweets downloaded so far\n",
      "...1158 tweets downloaded so far\n",
      "...1194 tweets downloaded so far\n",
      "...1194 tweets downloaded so far\n",
      "collecting tweets from: Cisco\n",
      "...376 tweets downloaded so far\n",
      "...551 tweets downloaded so far\n",
      "...734 tweets downloaded so far\n",
      "...895 tweets downloaded so far\n",
      "...1045 tweets downloaded so far\n",
      "...1196 tweets downloaded so far\n",
      "...1376 tweets downloaded so far\n",
      "...1543 tweets downloaded so far\n",
      "...1717 tweets downloaded so far\n",
      "...1887 tweets downloaded so far\n",
      "...2053 tweets downloaded so far\n",
      "...2190 tweets downloaded so far\n",
      "...2322 tweets downloaded so far\n",
      "...2487 tweets downloaded so far\n",
      "...2668 tweets downloaded so far\n",
      "...2720 tweets downloaded so far\n",
      "...2720 tweets downloaded so far\n",
      "collecting tweets from: CocaCola\n",
      "...205 tweets downloaded so far\n",
      "...220 tweets downloaded so far\n",
      "...235 tweets downloaded so far\n",
      "...245 tweets downloaded so far\n",
      "...256 tweets downloaded so far\n",
      "...263 tweets downloaded so far\n",
      "...269 tweets downloaded so far\n",
      "...271 tweets downloaded so far\n",
      "...278 tweets downloaded so far\n",
      "...281 tweets downloaded so far\n",
      "...286 tweets downloaded so far\n",
      "...299 tweets downloaded so far\n",
      "...302 tweets downloaded so far\n",
      "...303 tweets downloaded so far\n",
      "...308 tweets downloaded so far\n",
      "...321 tweets downloaded so far\n",
      "...321 tweets downloaded so far\n",
      "collecting tweets from: exxonmobil\n",
      "...387 tweets downloaded so far\n",
      "...586 tweets downloaded so far\n",
      "...774 tweets downloaded so far\n",
      "...962 tweets downloaded so far\n",
      "...1142 tweets downloaded so far\n",
      "...1296 tweets downloaded so far\n",
      "...1417 tweets downloaded so far\n",
      "...1510 tweets downloaded so far\n",
      "...1541 tweets downloaded so far\n",
      "...1602 tweets downloaded so far\n",
      "...1725 tweets downloaded so far\n",
      "...1923 tweets downloaded so far\n",
      "...2109 tweets downloaded so far\n",
      "...2289 tweets downloaded so far\n",
      "...2468 tweets downloaded so far\n",
      "...2530 tweets downloaded so far\n",
      "...2530 tweets downloaded so far\n",
      "collecting tweets from: generalelectric\n",
      "...364 tweets downloaded so far\n",
      "...540 tweets downloaded so far\n",
      "...708 tweets downloaded so far\n",
      "...849 tweets downloaded so far\n",
      "...1008 tweets downloaded so far\n",
      "...1191 tweets downloaded so far\n",
      "...1352 tweets downloaded so far\n",
      "...1497 tweets downloaded so far\n",
      "...1626 tweets downloaded so far\n",
      "...1746 tweets downloaded so far\n",
      "...1839 tweets downloaded so far\n",
      "...1948 tweets downloaded so far\n",
      "...2011 tweets downloaded so far\n",
      "...2056 tweets downloaded so far\n",
      "...2109 tweets downloaded so far\n",
      "...2136 tweets downloaded so far\n",
      "...2136 tweets downloaded so far\n",
      "collecting tweets from: GoldmanSachs\n",
      "...358 tweets downloaded so far\n",
      "...544 tweets downloaded so far\n",
      "...735 tweets downloaded so far\n",
      "...925 tweets downloaded so far\n",
      "...1112 tweets downloaded so far\n",
      "...1312 tweets downloaded so far\n",
      "...1511 tweets downloaded so far\n",
      "...1711 tweets downloaded so far\n",
      "...1911 tweets downloaded so far\n",
      "...2111 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...2310 tweets downloaded so far\n",
      "...2510 tweets downloaded so far\n",
      "...2710 tweets downloaded so far\n",
      "...2910 tweets downloaded so far\n",
      "...3110 tweets downloaded so far\n",
      "...3160 tweets downloaded so far\n",
      "...3160 tweets downloaded so far\n",
      "collecting tweets from: IBM\n",
      "...217 tweets downloaded so far\n",
      "...231 tweets downloaded so far\n",
      "...254 tweets downloaded so far\n",
      "...278 tweets downloaded so far\n",
      "...290 tweets downloaded so far\n",
      "...295 tweets downloaded so far\n",
      "...304 tweets downloaded so far\n",
      "...319 tweets downloaded so far\n",
      "...328 tweets downloaded so far\n",
      "...336 tweets downloaded so far\n",
      "...347 tweets downloaded so far\n",
      "...358 tweets downloaded so far\n",
      "...371 tweets downloaded so far\n",
      "...381 tweets downloaded so far\n",
      "...396 tweets downloaded so far\n",
      "...407 tweets downloaded so far\n",
      "...407 tweets downloaded so far\n",
      "collecting tweets from: intel\n",
      "...338 tweets downloaded so far\n",
      "...440 tweets downloaded so far\n",
      "...522 tweets downloaded so far\n",
      "...572 tweets downloaded so far\n",
      "...636 tweets downloaded so far\n",
      "...698 tweets downloaded so far\n",
      "...737 tweets downloaded so far\n",
      "...783 tweets downloaded so far\n",
      "...818 tweets downloaded so far\n",
      "...883 tweets downloaded so far\n",
      "...956 tweets downloaded so far\n",
      "...1043 tweets downloaded so far\n",
      "...1114 tweets downloaded so far\n",
      "...1219 tweets downloaded so far\n",
      "...1347 tweets downloaded so far\n",
      "...1401 tweets downloaded so far\n",
      "...1401 tweets downloaded so far\n",
      "collecting tweets from: JNJNews\n",
      "...242 tweets downloaded so far\n",
      "...327 tweets downloaded so far\n",
      "...357 tweets downloaded so far\n",
      "...411 tweets downloaded so far\n",
      "...483 tweets downloaded so far\n",
      "...634 tweets downloaded so far\n",
      "...790 tweets downloaded so far\n",
      "...946 tweets downloaded so far\n",
      "...1081 tweets downloaded so far\n",
      "...1256 tweets downloaded so far\n",
      "...1414 tweets downloaded so far\n",
      "...1557 tweets downloaded so far\n",
      "...1710 tweets downloaded so far\n",
      "...1860 tweets downloaded so far\n",
      "...1972 tweets downloaded so far\n",
      "...1977 tweets downloaded so far\n",
      "...1977 tweets downloaded so far\n",
      "collecting tweets from: jpmorgan\n",
      "...362 tweets downloaded so far\n",
      "...502 tweets downloaded so far\n",
      "...658 tweets downloaded so far\n",
      "...825 tweets downloaded so far\n",
      "...1017 tweets downloaded so far\n",
      "...1208 tweets downloaded so far\n",
      "...1401 tweets downloaded so far\n",
      "...1596 tweets downloaded so far\n",
      "...1787 tweets downloaded so far\n",
      "...1977 tweets downloaded so far\n",
      "...2167 tweets downloaded so far\n",
      "...2366 tweets downloaded so far\n",
      "...2565 tweets downloaded so far\n",
      "...2742 tweets downloaded so far\n",
      "...2938 tweets downloaded so far\n",
      "...2996 tweets downloaded so far\n",
      "...2996 tweets downloaded so far\n",
      "collecting tweets from: McDonalds\n",
      "...201 tweets downloaded so far\n",
      "...202 tweets downloaded so far\n",
      "...202 tweets downloaded so far\n",
      "collecting tweets from: Merck\n",
      "...391 tweets downloaded so far\n",
      "...587 tweets downloaded so far\n",
      "...759 tweets downloaded so far\n",
      "...932 tweets downloaded so far\n",
      "...1074 tweets downloaded so far\n",
      "...1077 tweets downloaded so far\n",
      "...1189 tweets downloaded so far\n",
      "...1383 tweets downloaded so far\n",
      "...1573 tweets downloaded so far\n",
      "...1711 tweets downloaded so far\n",
      "...1868 tweets downloaded so far\n",
      "...2055 tweets downloaded so far\n",
      "...2233 tweets downloaded so far\n",
      "...2420 tweets downloaded so far\n",
      "...2602 tweets downloaded so far\n",
      "...2746 tweets downloaded so far\n",
      "...2746 tweets downloaded so far\n",
      "collecting tweets from: Microsoft\n",
      "...248 tweets downloaded so far\n",
      "...318 tweets downloaded so far\n",
      "...369 tweets downloaded so far\n",
      "...423 tweets downloaded so far\n",
      "...468 tweets downloaded so far\n",
      "...512 tweets downloaded so far\n",
      "...562 tweets downloaded so far\n",
      "...614 tweets downloaded so far\n",
      "...672 tweets downloaded so far\n",
      "...728 tweets downloaded so far\n",
      "...777 tweets downloaded so far\n",
      "...825 tweets downloaded so far\n",
      "...870 tweets downloaded so far\n",
      "...917 tweets downloaded so far\n",
      "...953 tweets downloaded so far\n",
      "...990 tweets downloaded so far\n",
      "...990 tweets downloaded so far\n",
      "collecting tweets from: Nike\n",
      "...223 tweets downloaded so far\n",
      "...233 tweets downloaded so far\n",
      "...251 tweets downloaded so far\n",
      "...257 tweets downloaded so far\n",
      "...264 tweets downloaded so far\n",
      "...277 tweets downloaded so far\n",
      "...282 tweets downloaded so far\n",
      "...290 tweets downloaded so far\n",
      "...293 tweets downloaded so far\n",
      "...297 tweets downloaded so far\n",
      "...304 tweets downloaded so far\n",
      "...306 tweets downloaded so far\n",
      "...308 tweets downloaded so far\n",
      "...314 tweets downloaded so far\n",
      "...317 tweets downloaded so far\n",
      "...318 tweets downloaded so far\n",
      "...318 tweets downloaded so far\n",
      "collecting tweets from: pfizer\n",
      "...351 tweets downloaded so far\n",
      "...522 tweets downloaded so far\n",
      "...677 tweets downloaded so far\n",
      "...839 tweets downloaded so far\n",
      "...995 tweets downloaded so far\n",
      "...1167 tweets downloaded so far\n",
      "...1324 tweets downloaded so far\n",
      "...1474 tweets downloaded so far\n",
      "...1661 tweets downloaded so far\n",
      "...1850 tweets downloaded so far\n",
      "...2030 tweets downloaded so far\n",
      "...2204 tweets downloaded so far\n",
      "...2393 tweets downloaded so far\n",
      "...2586 tweets downloaded so far\n",
      "...2778 tweets downloaded so far\n",
      "...2828 tweets downloaded so far\n",
      "...2828 tweets downloaded so far\n",
      "collecting tweets from: ProcterGamble\n",
      "...259 tweets downloaded so far\n",
      "...348 tweets downloaded so far\n",
      "...374 tweets downloaded so far\n",
      "...404 tweets downloaded so far\n",
      "...468 tweets downloaded so far\n",
      "...548 tweets downloaded so far\n",
      "...624 tweets downloaded so far\n",
      "...701 tweets downloaded so far\n",
      "...782 tweets downloaded so far\n",
      "...859 tweets downloaded so far\n",
      "...933 tweets downloaded so far\n",
      "...993 tweets downloaded so far\n",
      "...1061 tweets downloaded so far\n",
      "...1123 tweets downloaded so far\n",
      "...1203 tweets downloaded so far\n",
      "...1230 tweets downloaded so far\n",
      "...1230 tweets downloaded so far\n",
      "collecting tweets from: HomeDepot\n",
      "...365 tweets downloaded so far\n",
      "...504 tweets downloaded so far\n",
      "...679 tweets downloaded so far\n",
      "...838 tweets downloaded so far\n",
      "...1001 tweets downloaded so far\n",
      "...1106 tweets downloaded so far\n",
      "...1225 tweets downloaded so far\n",
      "...1311 tweets downloaded so far\n",
      "...1506 tweets downloaded so far\n",
      "...1690 tweets downloaded so far\n",
      "...1883 tweets downloaded so far\n",
      "...2081 tweets downloaded so far\n",
      "...2279 tweets downloaded so far\n",
      "...2474 tweets downloaded so far\n",
      "...2668 tweets downloaded so far\n",
      "...2726 tweets downloaded so far\n",
      "...2726 tweets downloaded so far\n",
      "collecting tweets from: Travelers\n",
      "...357 tweets downloaded so far\n",
      "...505 tweets downloaded so far\n",
      "...641 tweets downloaded so far\n",
      "...780 tweets downloaded so far\n",
      "...920 tweets downloaded so far\n",
      "...983 tweets downloaded so far\n",
      "...1127 tweets downloaded so far\n",
      "...1276 tweets downloaded so far\n",
      "...1380 tweets downloaded so far\n",
      "...1539 tweets downloaded so far\n",
      "...1708 tweets downloaded so far\n",
      "...1866 tweets downloaded so far\n",
      "...2025 tweets downloaded so far\n",
      "...2173 tweets downloaded so far\n",
      "...2326 tweets downloaded so far\n",
      "...2373 tweets downloaded so far\n",
      "...2373 tweets downloaded so far\n",
      "collecting tweets from: UTC\n",
      "...384 tweets downloaded so far\n",
      "...567 tweets downloaded so far\n",
      "...741 tweets downloaded so far\n",
      "...908 tweets downloaded so far\n",
      "...1094 tweets downloaded so far\n",
      "...1284 tweets downloaded so far\n",
      "...1471 tweets downloaded so far\n",
      "...1650 tweets downloaded so far\n",
      "...1837 tweets downloaded so far\n",
      "...2031 tweets downloaded so far\n",
      "...2213 tweets downloaded so far\n",
      "...2397 tweets downloaded so far\n",
      "...2575 tweets downloaded so far\n",
      "...2768 tweets downloaded so far\n",
      "...2960 tweets downloaded so far\n",
      "...2962 tweets downloaded so far\n",
      "...2962 tweets downloaded so far\n",
      "collecting tweets from: UnitedHealthGrp\n",
      "...324 tweets downloaded so far\n",
      "...431 tweets downloaded so far\n",
      "...585 tweets downloaded so far\n",
      "...729 tweets downloaded so far\n",
      "...924 tweets downloaded so far\n",
      "...1108 tweets downloaded so far\n",
      "...1303 tweets downloaded so far\n",
      "...1502 tweets downloaded so far\n",
      "...1701 tweets downloaded so far\n",
      "...1898 tweets downloaded so far\n",
      "...2097 tweets downloaded so far\n",
      "...2297 tweets downloaded so far\n",
      "...2497 tweets downloaded so far\n",
      "...2695 tweets downloaded so far\n",
      "...2761 tweets downloaded so far\n",
      "...2761 tweets downloaded so far\n",
      "collecting tweets from: verizon\n",
      "...310 tweets downloaded so far\n",
      "...407 tweets downloaded so far\n",
      "...473 tweets downloaded so far\n",
      "...529 tweets downloaded so far\n",
      "...595 tweets downloaded so far\n",
      "...629 tweets downloaded so far\n",
      "...654 tweets downloaded so far\n",
      "...674 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...729 tweets downloaded so far\n",
      "...745 tweets downloaded so far\n",
      "...853 tweets downloaded so far\n",
      "...948 tweets downloaded so far\n",
      "...1037 tweets downloaded so far\n",
      "...1116 tweets downloaded so far\n",
      "...1191 tweets downloaded so far\n",
      "...1232 tweets downloaded so far\n",
      "...1232 tweets downloaded so far\n",
      "collecting tweets from: Visa\n",
      "...235 tweets downloaded so far\n",
      "...253 tweets downloaded so far\n",
      "...257 tweets downloaded so far\n",
      "...258 tweets downloaded so far\n",
      "...259 tweets downloaded so far\n",
      "...261 tweets downloaded so far\n",
      "...262 tweets downloaded so far\n",
      "...263 tweets downloaded so far\n",
      "...330 tweets downloaded so far\n",
      "...330 tweets downloaded so far\n",
      "collecting tweets from: Walmart\n",
      "...226 tweets downloaded so far\n",
      "...227 tweets downloaded so far\n",
      "...229 tweets downloaded so far\n",
      "...231 tweets downloaded so far\n",
      "...232 tweets downloaded so far\n",
      "...234 tweets downloaded so far\n",
      "...239 tweets downloaded so far\n",
      "...240 tweets downloaded so far\n",
      "...243 tweets downloaded so far\n",
      "...249 tweets downloaded so far\n",
      "...258 tweets downloaded so far\n",
      "...260 tweets downloaded so far\n",
      "...262 tweets downloaded so far\n",
      "...264 tweets downloaded so far\n",
      "...264 tweets downloaded so far\n",
      "collecting tweets from: DisneyStudios\n",
      "...366 tweets downloaded so far\n",
      "...541 tweets downloaded so far\n",
      "...725 tweets downloaded so far\n",
      "...900 tweets downloaded so far\n",
      "...1088 tweets downloaded so far\n",
      "...1275 tweets downloaded so far\n",
      "...1443 tweets downloaded so far\n",
      "...1635 tweets downloaded so far\n",
      "...1820 tweets downloaded so far\n",
      "...1997 tweets downloaded so far\n",
      "...2188 tweets downloaded so far\n",
      "...2379 tweets downloaded so far\n",
      "...2547 tweets downloaded so far\n",
      "...2732 tweets downloaded so far\n",
      "...2915 tweets downloaded so far\n",
      "...2915 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "allData_list = []\n",
    "for acc in accounts:\n",
    "    allData_list.append(get_all_tweets(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1c95d9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'@doddthesod Hello Simon - We are sorry to see this. It is not what we would expect. Please connect with our UK supp\\xe2\\x80\\xa6 https://t.co/syixQ1BNQT'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData_df['tweets'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "61970f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "      <th>tweets</th>\n",
       "      <th>re_tweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-12 15:13:06+00:00</td>\n",
       "      <td>3M</td>\n",
       "      <td>https://twitter.com/3M/status/1558109327424163840</td>\n",
       "      <td>b'@doddthesod Hello Simon - We are sorry to se...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1558109327424163840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-11 20:49:19+00:00</td>\n",
       "      <td>3M</td>\n",
       "      <td>https://twitter.com/3M/status/1557831550422728705</td>\n",
       "      <td>b'@bleepingED Hello - Thank you for reaching o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1557831550422728705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-11 18:09:52+00:00</td>\n",
       "      <td>3M</td>\n",
       "      <td>https://twitter.com/3M/status/1557791422627123200</td>\n",
       "      <td>b'Did you know stop signs have not always been...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1557791422627123200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-11 16:32:22+00:00</td>\n",
       "      <td>3M</td>\n",
       "      <td>https://twitter.com/3M/status/1557766888775720960</td>\n",
       "      <td>b'No nails? No screws? No problem!\\n\\n@command...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1557766888775720960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-11 15:03:20+00:00</td>\n",
       "      <td>3M</td>\n",
       "      <td>https://twitter.com/3M/status/1557744482048770048</td>\n",
       "      <td>b'@crazypnut Hello - Thank you for reaching ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1557744482048770048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55190</th>\n",
       "      <td>2019-04-07 19:06:00+00:00</td>\n",
       "      <td>Walt Disney</td>\n",
       "      <td>https://twitter.com/DisneyStudios/status/11149...</td>\n",
       "      <td>b'In Dreamland, everything is possible. See #D...</td>\n",
       "      <td>104</td>\n",
       "      <td>937</td>\n",
       "      <td>1114967577883762691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55191</th>\n",
       "      <td>2019-04-07 16:00:00+00:00</td>\n",
       "      <td>Walt Disney</td>\n",
       "      <td>https://twitter.com/DisneyStudios/status/11149...</td>\n",
       "      <td>b'Celebrate 10 years of @Disneynature in advan...</td>\n",
       "      <td>100</td>\n",
       "      <td>734</td>\n",
       "      <td>1114920771753844736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55192</th>\n",
       "      <td>2019-04-06 19:00:00+00:00</td>\n",
       "      <td>Walt Disney</td>\n",
       "      <td>https://twitter.com/DisneyStudios/status/11146...</td>\n",
       "      <td>b'See the #1 movie in the world, in theaters n...</td>\n",
       "      <td>51</td>\n",
       "      <td>522</td>\n",
       "      <td>1114603682195095553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55193</th>\n",
       "      <td>2019-04-06 18:00:01+00:00</td>\n",
       "      <td>Walt Disney</td>\n",
       "      <td>https://twitter.com/DisneyStudios/status/11145...</td>\n",
       "      <td>b'There\\xe2\\x80\\x99s no one quite like Steve. ...</td>\n",
       "      <td>207</td>\n",
       "      <td>1340</td>\n",
       "      <td>1114588585485918208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55194</th>\n",
       "      <td>2019-04-06 17:00:00+00:00</td>\n",
       "      <td>Walt Disney</td>\n",
       "      <td>https://twitter.com/DisneyStudios/status/11145...</td>\n",
       "      <td>b'Have you met the newest performer? See #Dumb...</td>\n",
       "      <td>84</td>\n",
       "      <td>882</td>\n",
       "      <td>1114573481432084482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55195 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     created_at      company  \\\n",
       "0     2022-08-12 15:13:06+00:00           3M   \n",
       "1     2022-08-11 20:49:19+00:00           3M   \n",
       "2     2022-08-11 18:09:52+00:00           3M   \n",
       "3     2022-08-11 16:32:22+00:00           3M   \n",
       "4     2022-08-11 15:03:20+00:00           3M   \n",
       "...                         ...          ...   \n",
       "55190 2019-04-07 19:06:00+00:00  Walt Disney   \n",
       "55191 2019-04-07 16:00:00+00:00  Walt Disney   \n",
       "55192 2019-04-06 19:00:00+00:00  Walt Disney   \n",
       "55193 2019-04-06 18:00:01+00:00  Walt Disney   \n",
       "55194 2019-04-06 17:00:00+00:00  Walt Disney   \n",
       "\n",
       "                                                     url  \\\n",
       "0      https://twitter.com/3M/status/1558109327424163840   \n",
       "1      https://twitter.com/3M/status/1557831550422728705   \n",
       "2      https://twitter.com/3M/status/1557791422627123200   \n",
       "3      https://twitter.com/3M/status/1557766888775720960   \n",
       "4      https://twitter.com/3M/status/1557744482048770048   \n",
       "...                                                  ...   \n",
       "55190  https://twitter.com/DisneyStudios/status/11149...   \n",
       "55191  https://twitter.com/DisneyStudios/status/11149...   \n",
       "55192  https://twitter.com/DisneyStudios/status/11146...   \n",
       "55193  https://twitter.com/DisneyStudios/status/11145...   \n",
       "55194  https://twitter.com/DisneyStudios/status/11145...   \n",
       "\n",
       "                                                  tweets re_tweets likes  \\\n",
       "0      b'@doddthesod Hello Simon - We are sorry to se...         0     0   \n",
       "1      b'@bleepingED Hello - Thank you for reaching o...         0     1   \n",
       "2      b'Did you know stop signs have not always been...         2    11   \n",
       "3      b'No nails? No screws? No problem!\\n\\n@command...         2    11   \n",
       "4      b'@crazypnut Hello - Thank you for reaching ou...         0     0   \n",
       "...                                                  ...       ...   ...   \n",
       "55190  b'In Dreamland, everything is possible. See #D...       104   937   \n",
       "55191  b'Celebrate 10 years of @Disneynature in advan...       100   734   \n",
       "55192  b'See the #1 movie in the world, in theaters n...        51   522   \n",
       "55193  b'There\\xe2\\x80\\x99s no one quite like Steve. ...       207  1340   \n",
       "55194  b'Have you met the newest performer? See #Dumb...        84   882   \n",
       "\n",
       "                        id  \n",
       "0      1558109327424163840  \n",
       "1      1557831550422728705  \n",
       "2      1557791422627123200  \n",
       "3      1557766888775720960  \n",
       "4      1557744482048770048  \n",
       "...                    ...  \n",
       "55190  1114967577883762691  \n",
       "55191  1114920771753844736  \n",
       "55192  1114603682195095553  \n",
       "55193  1114588585485918208  \n",
       "55194  1114573481432084482  \n",
       "\n",
       "[55195 rows x 7 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData_df = pd.concat(allData_list).reset_index(drop=True)\n",
    "allData_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a1f08bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whwen\\AppData\\Local\\Temp/ipykernel_12952/3633397753.py:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  allData_df.describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "      <th>tweets</th>\n",
       "      <th>re_tweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>55195</td>\n",
       "      <td>55195</td>\n",
       "      <td>55195</td>\n",
       "      <td>55195</td>\n",
       "      <td>55195.0</td>\n",
       "      <td>55195.0</td>\n",
       "      <td>55195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>54753</td>\n",
       "      <td>33</td>\n",
       "      <td>55195</td>\n",
       "      <td>55058</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>2033.0</td>\n",
       "      <td>55195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2022-08-08 14:18:14+00:00</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>https://twitter.com/3M/status/1558109327424163840</td>\n",
       "      <td>b'Here are 5 ways Amgen supports the environme...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1558109327424163840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>3160</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>12192.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2012-05-17 12:48:23+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2022-08-13 13:15:04+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at        company  \\\n",
       "count                       55195          55195   \n",
       "unique                      54753             33   \n",
       "top     2022-08-08 14:18:14+00:00  Goldman Sachs   \n",
       "freq                            4           3160   \n",
       "first   2012-05-17 12:48:23+00:00            NaN   \n",
       "last    2022-08-13 13:15:04+00:00            NaN   \n",
       "\n",
       "                                                      url  \\\n",
       "count                                               55195   \n",
       "unique                                              55195   \n",
       "top     https://twitter.com/3M/status/1558109327424163840   \n",
       "freq                                                    1   \n",
       "first                                                 NaN   \n",
       "last                                                  NaN   \n",
       "\n",
       "                                                   tweets  re_tweets    likes  \\\n",
       "count                                               55195    55195.0  55195.0   \n",
       "unique                                              55058     1026.0   2033.0   \n",
       "top     b'Here are 5 ways Amgen supports the environme...        0.0      0.0   \n",
       "freq                                                   10     5612.0  12192.0   \n",
       "first                                                 NaN        NaN      NaN   \n",
       "last                                                  NaN        NaN      NaN   \n",
       "\n",
       "                         id  \n",
       "count                 55195  \n",
       "unique                55195  \n",
       "top     1558109327424163840  \n",
       "freq                      1  \n",
       "first                   NaN  \n",
       "last                    NaN  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2cd04a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "allData_df.to_pickle(\"Merge_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "05ae4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2022-06-01\"\n",
    "start_date = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "end_date = \"2022-07-01\"\n",
    "end_date = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "# Right way!\n",
    "start_date = start_date.replace(tzinfo=timezone('UTC'))\n",
    "end_date = end_date.replace(tzinfo=timezone('UTC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2c830dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-01 00:00:00+00:00\n",
      "2022-07-01 00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "print(start_date)\n",
    "print(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ba776d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "      <th>tweets</th>\n",
       "      <th>re_tweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-30 18:50:06+00:00</td>\n",
       "      <td>3M</td>\n",
       "      <td>https://twitter.com/3M/status/1542581260689833986</td>\n",
       "      <td>b'Happy #SocialMediaDay \\xf0\\x9f\\x93\\xb1 Join ...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1542581260689833986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-30 17:43:50+00:00</td>\n",
       "      <td>3M</td>\n",
       "      <td>https://twitter.com/3M/status/1542564580563582982</td>\n",
       "      <td>b\"@sevenpiggies Hello - Thank you for messagin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1542564580563582982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-29 17:28:44+00:00</td>\n",
       "      <td>3M</td>\n",
       "      <td>https://twitter.com/3M/status/1542198395275706369</td>\n",
       "      <td>b'@ohunt Sorry to hear of the difficulty! Plea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1542198395275706369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-29 17:01:30+00:00</td>\n",
       "      <td>3M</td>\n",
       "      <td>https://twitter.com/3M/status/1542191540227002370</td>\n",
       "      <td>b'See how artist @gabe_gault uses artificial r...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1542191540227002370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-29 16:56:50+00:00</td>\n",
       "      <td>3M</td>\n",
       "      <td>https://twitter.com/3M/status/1542190367130402821</td>\n",
       "      <td>b'@mochesa Hello! The 3M Kenya help center can...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1542190367130402821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>2022-06-03 16:00:04+00:00</td>\n",
       "      <td>Walt Disney</td>\n",
       "      <td>https://twitter.com/DisneyStudios/status/15327...</td>\n",
       "      <td>b'\\xf0\\x9f\\x8e\\xb6 ...all the flowers and vine...</td>\n",
       "      <td>29</td>\n",
       "      <td>153</td>\n",
       "      <td>1532753996456374274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>2022-06-03 15:00:03+00:00</td>\n",
       "      <td>Walt Disney</td>\n",
       "      <td>https://twitter.com/DisneyStudios/status/15327...</td>\n",
       "      <td>b\"Here's to the dreamers! \\xf0\\x9f\\x92\\xab\\xf0...</td>\n",
       "      <td>28</td>\n",
       "      <td>187</td>\n",
       "      <td>1532738892004139008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>2022-06-02 19:30:41+00:00</td>\n",
       "      <td>Walt Disney</td>\n",
       "      <td>https://twitter.com/DisneyStudios/status/15324...</td>\n",
       "      <td>b\"LA state of mind. \\xe2\\x98\\x80\\xef\\xb8\\x8f\\x...</td>\n",
       "      <td>20</td>\n",
       "      <td>168</td>\n",
       "      <td>1532444613109174272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>2022-06-02 17:00:02+00:00</td>\n",
       "      <td>Walt Disney</td>\n",
       "      <td>https://twitter.com/DisneyStudios/status/15324...</td>\n",
       "      <td>b'We all have our own stories to tell \\xf0\\x9f...</td>\n",
       "      <td>18</td>\n",
       "      <td>162</td>\n",
       "      <td>1532406699599925266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>2022-06-01 16:00:05+00:00</td>\n",
       "      <td>Walt Disney</td>\n",
       "      <td>https://twitter.com/DisneyStudios/status/15320...</td>\n",
       "      <td>b'Lights, camera, action \\xf0\\x9f\\x8e\\xac\\xe2\\...</td>\n",
       "      <td>25</td>\n",
       "      <td>169</td>\n",
       "      <td>1532029224130707457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1795 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    created_at      company  \\\n",
       "0    2022-06-30 18:50:06+00:00           3M   \n",
       "1    2022-06-30 17:43:50+00:00           3M   \n",
       "2    2022-06-29 17:28:44+00:00           3M   \n",
       "3    2022-06-29 17:01:30+00:00           3M   \n",
       "4    2022-06-29 16:56:50+00:00           3M   \n",
       "...                        ...          ...   \n",
       "1790 2022-06-03 16:00:04+00:00  Walt Disney   \n",
       "1791 2022-06-03 15:00:03+00:00  Walt Disney   \n",
       "1792 2022-06-02 19:30:41+00:00  Walt Disney   \n",
       "1793 2022-06-02 17:00:02+00:00  Walt Disney   \n",
       "1794 2022-06-01 16:00:05+00:00  Walt Disney   \n",
       "\n",
       "                                                    url  \\\n",
       "0     https://twitter.com/3M/status/1542581260689833986   \n",
       "1     https://twitter.com/3M/status/1542564580563582982   \n",
       "2     https://twitter.com/3M/status/1542198395275706369   \n",
       "3     https://twitter.com/3M/status/1542191540227002370   \n",
       "4     https://twitter.com/3M/status/1542190367130402821   \n",
       "...                                                 ...   \n",
       "1790  https://twitter.com/DisneyStudios/status/15327...   \n",
       "1791  https://twitter.com/DisneyStudios/status/15327...   \n",
       "1792  https://twitter.com/DisneyStudios/status/15324...   \n",
       "1793  https://twitter.com/DisneyStudios/status/15324...   \n",
       "1794  https://twitter.com/DisneyStudios/status/15320...   \n",
       "\n",
       "                                                 tweets re_tweets likes  \\\n",
       "0     b'Happy #SocialMediaDay \\xf0\\x9f\\x93\\xb1 Join ...         2    16   \n",
       "1     b\"@sevenpiggies Hello - Thank you for messagin...         0     0   \n",
       "2     b'@ohunt Sorry to hear of the difficulty! Plea...         0     0   \n",
       "3     b'See how artist @gabe_gault uses artificial r...         0    15   \n",
       "4     b'@mochesa Hello! The 3M Kenya help center can...         0     1   \n",
       "...                                                 ...       ...   ...   \n",
       "1790  b'\\xf0\\x9f\\x8e\\xb6 ...all the flowers and vine...        29   153   \n",
       "1791  b\"Here's to the dreamers! \\xf0\\x9f\\x92\\xab\\xf0...        28   187   \n",
       "1792  b\"LA state of mind. \\xe2\\x98\\x80\\xef\\xb8\\x8f\\x...        20   168   \n",
       "1793  b'We all have our own stories to tell \\xf0\\x9f...        18   162   \n",
       "1794  b'Lights, camera, action \\xf0\\x9f\\x8e\\xac\\xe2\\...        25   169   \n",
       "\n",
       "                       id  \n",
       "0     1542581260689833986  \n",
       "1     1542564580563582982  \n",
       "2     1542198395275706369  \n",
       "3     1542191540227002370  \n",
       "4     1542190367130402821  \n",
       "...                   ...  \n",
       "1790  1532753996456374274  \n",
       "1791  1532738892004139008  \n",
       "1792  1532444613109174272  \n",
       "1793  1532406699599925266  \n",
       "1794  1532029224130707457  \n",
       "\n",
       "[1795 rows x 7 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData_df.query(' created_at >= @start_date and created_at <= @end_date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc10f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70836828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6ba30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31814cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82adc5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d8a589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1b06b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05a1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5444001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9873579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb6bd42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373eeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
